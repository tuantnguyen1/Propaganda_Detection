{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from preprocess_c import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "train_path  = 'data/data_propoganda/data/protechn_corpus_eval/train'\n",
    "test_path = 'data/data_propoganda/data/protechn_corpus_eval/test'\n",
    "dev_path = 'data/data_propoganda/data/protechn_corpus_eval/dev'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dset(path):\n",
    "    path_ = Path(path)\n",
    "    a = make_dataset(path_)\n",
    "    df_1 = pd.DataFrame(columns=['id','full_sent','start_sent','end_sent','start_prop','end_prop','prop','??','???'])\n",
    "    for dm in a:\n",
    "        df_t = pd.DataFrame(dm,columns =['id','full_sent','start_sent','end_sent','start_prop','end_prop','prop','??','???'] )\n",
    "        df_1 = df_1.append(df_t,ignore_index= True)\n",
    "    return df_1.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = make_dset(train_path)\n",
    "#df_train= pd.read_csv('Context_only (1).csv')\n",
    "df_test = make_dset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = [0 if i == 'O' else 1 for i in df_train.prop.values ]\n",
    "df_train['binary'] = bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {'Loaded_Language':1,'Name_Calling,Labeling':2,'Repetition':3,\n",
    "           'Exaggeration,Minimisation':4,'Doubt':5,'Appeal_to_fear-prejudice':6,'Flag-Waving':7,'Causal_Oversimplification':8,\n",
    "           'Slogans':9,'Appeal_to_Authority':10,'Black-and-White_Fallacy':11,'Thought-terminating_Cliches':12,'Whataboutism':13,\n",
    "           'Reductio_ad_hitlerum':14,'Red_Herring':15,'Bandwagon':16,'Obfuscation,Intentional_Vagueness,Confusion':17,'Straw_Men':18,'O':0}\n",
    "#df_train = df_train[df_train.binary !=0]\n",
    "\n",
    "df_train['prop_1'] = df_train.prop.apply(lambda x: mapping[x])\n",
    "df_test['prop_1'] = df_test.prop.apply(lambda x: mapping[x])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "train_direct = glob.glob('data/data_propoganda/data/protechn_corpus_eval/train/*.txt')\n",
    "articles = []\n",
    "def read_articles():\n",
    "  for filename in train_direct:\n",
    "    myfile = open(filename)\n",
    "    article = myfile.read()\n",
    "    articles.append(article)\n",
    "    myfile.close()\n",
    "  article_ids = []\n",
    "  for filename in train_direct:\n",
    "    article_ids.append(filename[60:-4])\n",
    "  \n",
    "  return articles, article_ids\n",
    "articles,art_ids = read_articles()\n",
    "id2art ={i:a for a,i in zip(articles,art_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(article, span, mode='sentence'):\n",
    "  article = id2art[article]\n",
    "  def get_num_words(sentence):\n",
    "    return len(sentence.split(' '))\n",
    "  if mode == \"title\":\n",
    "    return article.split('\\n')[0]\n",
    "  if mode == \"sentence\":\n",
    "    WORD_LEN_LIMIT = 120\n",
    "    li = span[0]\n",
    "    ri = span[1]\n",
    "    span_text = article[li: ri]\n",
    "    num_words = get_num_words(span_text)\n",
    "    if num_words >= WORD_LEN_LIMIT:\n",
    "      return span_text\n",
    "    remaining_len = WORD_LEN_LIMIT - num_words\n",
    "    lhs_words = remaining_len // 2\n",
    "    rhs_words = remaining_len - lhs_words\n",
    "    li -= 1\n",
    "    lcount = 0\n",
    "    while li >= 0 and article[li-1] != '\\n' and lcount < lhs_words:\n",
    "      if article[li] == ' ':\n",
    "        lcount += 1\n",
    "      li -= 1\n",
    "    ri += 1\n",
    "    rcount = 0\n",
    "    while ri < len(article) and article[ri] != '\\n' and rcount < rhs_words:\n",
    "      if article[ri] == ' ':\n",
    "        rcount += 1\n",
    "      ri += 1\n",
    "    return article[li+1: ri - 1] \n",
    "\n",
    "  return \"\"\n",
    "spans_1 = [(i,k,j) for i,k,j in zip(df_train.id,df_train.start_sent,df_train.end_sent)]\n",
    "df_train['context'] = [get_context(i,(s,e)) for i,s,e in spans_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.full_sent[index])\n",
    "        title = \" \".join(title.split())\n",
    "        context = str(self.data.context[index])\n",
    "        context = \" \".join(context.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        tokenized_context = self.tokenizer.encode_plus(context,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,truncation = True)\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        c_ids = tokenized_context['input_ids']\n",
    "        c_mask = tokenized_context['attention_mask']\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.prop_1[index], dtype=torch.long),\n",
    "            'c_ids':torch.tensor(c_ids, dtype=torch.long),\n",
    "            'c_mask': torch.tensor(c_mask,dtype= torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15750, 10)\n",
      "TRAIN Dataset: (12600, 10)\n",
      "TEST Dataset: (3150, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=df_train.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df_train.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df_train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, MSELoss,BCEWithLogitsLoss\n",
    "\n",
    "class ContextualBertForSequenceClassification(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, num_labels, ContextModel, SpanModel):\n",
    "    super(ContextualBertForSequenceClassification, self).__init__()\n",
    "    self.ContextModel = ContextModel\n",
    "    self.SpanModel = SpanModel\n",
    "    self.num_labels = num_labels\n",
    "\n",
    "    # self.classifier = torch.nn.Linear(768*2, num_labels)\n",
    "    # self.classifier1 = torch.nn.Linear(768, num_labels)\n",
    "    self.classifier2 = torch.nn.Linear(768+128, num_labels)\n",
    "    self.reduce_classifier = torch.nn.Linear(768, 128)\n",
    "    self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      span_input_ids,\n",
    "      span_attention_mask,\n",
    "      context_input_ids,\n",
    "      context_attention_mask,\n",
    "      labels=None\n",
    "  ):\n",
    "    context_outputs = self.ContextModel(\n",
    "        input_ids=context_input_ids,\n",
    "        attention_mask=context_attention_mask\n",
    "    )\n",
    "    context_outputs = context_outputs[1] # pooler output\n",
    "    span_outputs = self.SpanModel(\n",
    "        input_ids=span_input_ids,\n",
    "        attention_mask=span_attention_mask\n",
    "    )\n",
    "    span_outputs = span_outputs[1]\n",
    "\n",
    "    context_outputs = self.reduce_classifier(context_outputs)\n",
    "    pooled_output = torch.cat((span_outputs, context_outputs), axis=1)\n",
    "\n",
    "    pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "    logits = self.classifier2(pooled_output)\n",
    "    outputs = (logits,)\n",
    "    if labels is not None:\n",
    "      if self.num_labels == 1:\n",
    "        loss_fct = MSELoss()\n",
    "        loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "      else:\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "      outputs = (loss,) + outputs\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  labels_flat = labels.flatten()\n",
    "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5):\n",
    "  loss_values = []\n",
    "  for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(training_loader):\n",
    "      if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(training_loader), elapsed))\n",
    "      b_input_ids = batch['ids'].to(device)\n",
    "      b_labels = batch['targets'].to(device, dtype = torch.long)\n",
    "      b_input_mask = batch['mask'].to(device)\n",
    "      b_c_input_ids = batch['c_ids'].to(device)\n",
    "      b_c_input_mask = batch['c_mask'].to(device)\n",
    "      model.zero_grad()        \n",
    "      outputs = model(b_input_ids, \n",
    "                      b_input_mask,\n",
    "                      b_c_input_ids, \n",
    "                      b_c_input_mask, \n",
    "                      labels=b_labels)\n",
    "      loss = outputs[0]\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "      scheduler.step() # TODO\n",
    "      stats = '[%d/%d][%d/%d]\\tLoss: %.4f' \\\n",
    "                % (epoch_i+1, epochs, step, len(training_loader), loss.item())\n",
    "      print('\\r' + stats, end=\"\")\n",
    "      sys.stdout.flush()\n",
    "    avg_train_loss = total_loss / len(training_loader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in testing_loader:\n",
    "      # batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids = batch['ids'].to(device)\n",
    "      b_labels = batch['targets'].to(device, dtype = torch.long)\n",
    "      b_input_mask = batch['mask'].to(device)\n",
    "      b_c_input_ids = batch['c_ids'].to(device)\n",
    "      b_c_input_mask = batch['c_mask'].to(device)\n",
    "      with torch.no_grad():        \n",
    "        outputs = model(b_input_ids, \n",
    "                        b_input_mask,\n",
    "                        b_c_input_ids, \n",
    "                        b_c_input_mask)\n",
    "      logits = outputs[0]\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "      eval_accuracy += tmp_eval_accuracy\n",
    "      nb_eval_steps += 1\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "  print(\"\")\n",
    "  print(\"Training complete!\")\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(model, dataloader):\n",
    "  model.eval()\n",
    "  predictions , true_labels = [], []\n",
    "  nb_eval_steps = 0\n",
    "  for batch in dataloader:\n",
    "    b_input_ids = batch['ids'].to(device)\n",
    "    b_labels = batch['targets'].to(device)\n",
    "    b_input_mask = batch['mask'].to(device)\n",
    "    b_c_input_ids = batch['c_ids'].to(device)\n",
    "    b_c_input_mask = batch['c_mask'].to(device)\n",
    "    with torch.no_grad():        \n",
    "      logits = model(b_input_ids, \n",
    "                     b_input_mask,\n",
    "                     b_c_input_ids, \n",
    "                     b_c_input_mask)\n",
    "    \n",
    "    logits = logits[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    pred_label = np.argmax(logits, axis=1) #[1 if a >0.5 else 0 for a in logits]\n",
    "    predictions.extend(pred_label)\n",
    "    true_labels.extend(label_ids)\n",
    "  return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dev_predictions(model):\n",
    "  test_articles, _ = read_articles(\"dev-articles\")\n",
    "  test_spans, test_techniques = read_test_spans()\n",
    "\n",
    "  test_articles = test_articles[1:]\n",
    "  test_dataloader = get_data(test_articles, test_spans, test_techniques)\n",
    "  pred, _ = get_model_predictions(model, test_dataloader)\n",
    "\n",
    "  with open('predictions.txt', 'w') as fp:\n",
    "    label_file = os.path.join(data_dir, \"dev-task-TC-template.out\")\n",
    "    myfile = open(label_file)\n",
    "    prev_index = -1\n",
    "    tsvreader = csv.reader(myfile, delimiter=\"\\t\")\n",
    "    for i, row in enumerate(tsvreader):\n",
    "      fp.write(row[0] + '\\t' + distinct_techniques[pred[i]] + '\\t' + row[2] + '\\t' + row[3] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 7 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/56/nguyent84/unix/.conda/envs/concacenvi/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7][3/394]\tLoss: 2.6303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-47608d4633cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                             \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Default value in run_glue.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                             num_training_steps = total_steps)\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-da1a427d603c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[%d/%d][%d/%d]\\tLoss: %.4f'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concacenvi/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concacenvi/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#from transformers import RobertaModel\n",
    "from transformers import BertModel\n",
    "#from transformers import RobertaForSequenceClassification\n",
    "import time,sys\n",
    "\n",
    "model_name = 'bert-base-cased'\n",
    "context_model = BertModel.from_pretrained(model_name)\n",
    "span_model = BertModel.from_pretrained(model_name)\n",
    "model = ContextualBertForSequenceClassification(19, context_model, span_model)\n",
    "model.cuda()\n",
    "\"\"\"model.load_state_dict(torch.load('best.pth'))\n",
    "model.eval()\"\"\"\n",
    "optimizer = AdamW(model.parameters(),lr = 3e-5,eps = 1e-8) # ler = 5e-5\n",
    "epochs = 7\n",
    "\n",
    "total_steps = len(training_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "train(model, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in model if saved. ('best.pth' is the model name)\n",
    "\"\"\"model.load_state_dict(torch.load('best.pth'))\n",
    "model.eval()\"\"\"\n",
    "\n",
    "#predict and get classification report\n",
    "\"\"\"pred,true = get_model_predictions(model,testing_loader)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pred,true))\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "concacenvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
